<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Filter Aesthetic Comparison Dataset</title>
    <link rel="stylesheet" href="http://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css">
    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-52062463-2', 'auto');
        ga('send', 'pageview');
    </script>
    <script>
        $(document).ready(function(){
            $('.download').on('click', function() {
                ga('send', 'event', 'Downloads', 'Download', $(this).attr('id'));
            });
        });
    </script>
</head>

<body>
<div class="container">
    <div class="row">
        <div class="col-md-12">
            <h2>Cross-Age Reference Coding for Age-Invariant Face Recognition and Retrieval</h2>
            <h4>
            <a href="http://cmlab.csie.ntu.edu.tw/~sirius42/">Bor-Chun Chen</a>, 
            <a href="http://www.iis.sinica.edu.tw/pages/song/index_en.html">Chu-Song Chen</a>, 
            <a href="http://www.csie.ntu.edu.tw/~winston/">Winston Hsu</a>
            </h4>
        </div>
    </div>
    <div class="row">
        <div class="col-md-5">
            <img src="fig_example.jpg" class="img-responsive"/>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>Abstract</h3>
            Nowadays, social media have become popular platforms for the public to share photos. To apply effects on a photo or improve its quality, most social media provide filters by which users can change the appearance of their photos without domain knowledge. However, due to the growing number of filter types, it becomes a major issue for users to choose the best filter type instantly. For this purpose, learning image aesthetics takes an important role in image quality ranking problems. In these years, several research has proved that Convolutional Neural Networks (CNNs) outperform traditional methods in image aesthetic categorization, which classifies images into high or low quality. In this paper, we introduce a new method for image quality learning and a dataset of filtered images with comparison. Instead of binarizing image quality, we use different CNN architectures and a pairwise comparison loss function to learn the aesthetic response for an image. By utilizing pairwise image comparison, the models embed aesthetic responses in the hidden layers. Moreover, to improve the aesthetic ranking, the image category is integreated into the aesthetic-oriented models. To train our models and evaluate our method, we introduce a new dataset called Filter Aesthetic Comparison Dataset (FACD). The dataset contains more than 30,000 filtered images based on the AVA dataset and more than 40,000 image pairs with quality comparison annotations using Amazon Mechanical Turk. To our best knowledge, it is the first dataset containing filtered images and the user preference labels. The experimental results show that our method which learns aesthetic ranking by pairwise comparison outperforms the traditional aesthetic classification methods. 
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>Publication</h3>
            <ul>
            <li>
            <p>
            Bor-Chun Chen, Chu-Song Chen, Winston H. Hsu. Cross-Age Reference Coding for Age-Invariant Face Recognition and Retrieval, ECCV 2014 
            [<a href="http://cmlab.csie.ntu.edu.tw/~sirius42/papers/chen14eccv.pdf">Pdf</a>]
            [<a data-toggle="collapse" data-target="#bibtex">Bibtex</a>]
            <div id="bibtex" class="well collapse">
                @inproceedings{chen14cross, <br />
                Author = {Bor-Chun Chen and Chu-Song Chen and Winston H. Hsu}, <br />
                Booktitle = {Proceedings of the European Conference on Computer Vision ({ECCV})}, <br />
                Title = {Cross-Age Reference Coding for Age-Invariant Face Recognition and Retrieval}, <br />
                Year = {2014} <br />
                } 
            </div>
            </p>
            </li>
            <li>
            <p>
            Bor-Chun Chen, Chu-Song Chen, Winston H. Hsu. Face Recognition using Cross-Age Reference Coding with Cross-Age Celebrity Dataset, IEEE Transactions on Multimedia, 2015. (accepted) [<a href="http://www.umiacs.umd.edu/~sirius/papers/chen14tmm.pdf">pdf</a>]
            </p>
            </li>
            </ul>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>Dataset</h3>
            <h5 class="text-danger"> Please notice that this dataset is made available for academic research purpose only. All the images are collected from the Internet, and the copyright belongs to the original owners. If any of the images belongs to you and you would like it removed, please kindly inform <a href="mailto:bcsiriuschen@gmail.com">us</a>, we will remove it from our dataset immediately.</h5>
            <h4>Cross-Age Celebrity Dataset (CACD)</h4>
            Cross-Age Celebrity Dataset (CACD) contains 163,446 images from 2,000 celebrities collected from the Internet. The images are collected from search engines using celebrity name and year (2004-2013) as keywords. We can therefore estimate the ages of the celebrities on the images by simply subtract the birth year from the year of which the photo was taken.
            The downloaded dataset contain two MATLAB structures:
            <div class="well">
                <ul class="list-unstyled">
                    <li>celebrityData - contains information of the 2,000 celebrities</li>
                        <ul>
                        <li>name - celebrity name</li>
                        <li>identity - celebrity id</li>
                        <li>birth - celebrity brith year</li>
                        <li>rank - rank of the celebrity with same birth year in IMDB.com when the dataset was constructed</li>
                        <li>lfw - whether the celebrity is in LFW dataset</li>
                        </ul>
                    <li>celebrityImageData - contains information of the face images</li>
                        <ul>
                        <li>age - estimated age of the celebrity</li>
                        <li>identity - celebrity id</li>
                        <li>year - estimated year of which the photo was taken</li>
                        <li>feature - 75,520 dimension LBP feature extracted from 16 facial landmarks</li>
                        <li>name - file name of the image</li>
                        </ul>
                </ul>
            </div>
            <ul>
            <li>The dataset metadata and features used in this paper can be downloaded [<a href="https://drive.google.com/file/d/0B3zF40otoXI3S1dBR0MtbWw5OVk/" class="download" id="CACD feature">here</a>] (4.4G)</li>
            <li>The dataset metadata only can be downloaded [<a href="http://www.umiacs.umd.edu/~sirius/CACD/celebrity2000_meta.mat" class="download" id="metadata">here</a>] (817K)</li>
            <li> Original face images (detected and croped by openCV face detector) can be downloaded [<a href="https://drive.google.com/file/d/0B3zF40otoXI3OTR0Y0MtNnVhNFU/" class="download" id="CACD image">here</a>] (3.5G)</li>
            <li>16 faical landmark locations used in this paper can be downloaded [<a href="https://docs.google.com/file/d/0B3zF40otoXI3dDFvSXlrZndqSVU/" class="download" id="CACD landmark">here</a>] (24M) (extracted by <a href="http://www.humansensing.cs.cmu.edu/intraface/">Intraface</a>)</li>
            </ul>
            <p>
            <h5>Notes</h5>
            *we manually removed noisy images from celebrities with rank smaller or equal to five. However, since some of the images are hard to identify even for humans, the dataset might still contains small noises. Also, we only employ very  simple duplicate detection method, so the dataset might still contain near-duplicate images. <br />
            *Images of other celebrities (with rank higher than five) will contain noises, so they should not be use for evaluation. <br />
            *The dataset is mainly designed for cross-age face recognition and retrieval. The year labels in the CACD dataset is rough and thus we do not suggest to apply it to age-estimation works. <br />
            </p>
            <p>
            <h4>Verification Subset (CACD-VS)</h4>
            We manually selected 2,000 positive cross-age image pairs and 2,000 negative pairs to form a subset for face verification task similar to the one used is LFW. The image pairs are carefully annotated by checking image content with surrdening text in the web pages. We evaluate the human preformance on this subset using Amazon Mechnical Turks. <br />

            The dataset contains 4,000 image pairs divided by ten folds. Identities in each fold are mutually exclusive. The images are named as pairId_0.jpg and pairId_1.jpg for each pair. First 400 image pairs [(0000_0.jpg,0000_1.jpg) - (0399_0.jpg,0399_1.jpg)] are first fold, in which first 200 image pairs (i.e. 0000 - 0199) are positive pairs and second 200 image pairs (i.e. 0200 - 0399) are negative pairs. The second fold contains image pair (0400 - 0799) and so on.
            </p>
            <ul>
            <li>Image pairs in verification subset (CACD-VS) can be downloaded [<a href="https://drive.google.com/open?id=0B3zF40otoXI3YUF3VUN4Mm5Hbms&authuser=0"  class="download" id="CACDVS image">here</a>] (198M) </li>
            <li>High dimensional LBP features (in .mat format) for CACD-VS can be downloaded [<a href="https://drive.google.com/open?id=0B3zF40otoXI3YWVrdFg4Y25wbE0&authuser=0" class="download" id="CACDVS feature">here</a>] (192M)</li>
            <li>Script (gnuplot) and data to generate the ROC curves in our TMM paper (Fig. 9) can be downloaded [<a href="https://drive.google.com/file/d/0B3zF40otoXI3cEVIVUxmSzF6bE0/view?usp=sharing" class="download" id="CACDVS ROC">here</a>] (18K)</li>
            </ul>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>Experimental Results</h3>
            <h4>Face retrieval performance on CACD</h4>
            Here we report the results using raw features (High-dimensional LBP) and the proposed methods (CARC) on face retrieval with three different subsets.
            In all three subsets, images taken in 2013 are used as query images. The database contains images taken in 2004-2006, 2007-2009, 2010-2012 for each of the three subsets respectively. All three subsets contains only images of celebrities with rank from 3 to 5.
            <div class="table-responsive">
            <table class="table table-bordered">
                <tr>
                    <td>Database</td>
                    <td colspan="2">2004-2006</td>
                    <td colspan="2">2007-2009</td>
                    <td colspan="2">2010-2012</td>
                </tr>
                <tr>
                    <td>Methods</td>
                    <td>MAP</td>
                    <td>p@1</td>
                    <td>MAP</td>
                    <td>p@1</td>
                    <td>MAP</td>
                    <td>p@1</td>
                </tr>
                <tr>
                    <td>High-Dimensional LBP</td>
                    <td>36.6%</td>
                    <td>78.0%</td>
                    <td>38.9%</td>
                    <td>80.3%</td>
                    <td>44.0%</td>
                    <td>85.5%</td>
                </tr>
                <tr>
                    <td>Cross-Age Reference Coding</td>
                    <td>52.9%</td>
                    <td>88.8%</td>
                    <td>55.5%</td>
                    <td>88.5%</td>
                    <td>61.1%</td>
                    <td>92.2%</td>
                </tr>
            </table>
            </div>
            <h4>Face verification performance on CACD-VS</h4>
            <div class="table-responsive">
            <table class="table table-bordered table-condensed">
                <tr>
                    <td> Method </td>
                    <td> Verification Accuracy </td>
                </tr>
                <tr>
                    <td>High-Dimensional LBP</td>
                    <td>81.6%</td>
                </tr>
                <tr>
                    <td>Hidden Factor Analysis</td>
                    <td>84.4%</td>
                </tr>
                <tr>
                    <td>Cross-Age Reference Coding</td>
                    <td>87.6%</td>
                </tr>
                <tr>
                    <td>Human, Average</td>
                    <td>85.7%</td>
                </tr>
                <tr>
                    <td>Human, Voting</td>
                    <td>94.2%</td>
                </tr>                                                                
            </table>
            </div>
            If you use our dataset and would like to report your results, please e-mail <a href="mailto:bcsiriuschen@gmail.com">Sirius Chen</a>. We will be gald to put your results on this webstie.
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>Code</h3>
            <p>
            For cross-age reference coding (CARC) code use in this paper, please visit [<a href="https://github.com/bcsiriuschen/CARC" class="download" id="CACD sources">here</a>]
            </p>
            <p>
            We also implemented the high-dimensional LBP features (Chen, Cao, Wen, and Sun, CVPR 2013), please visit [<a href="http://bcsiriuschen.github.io/High-Dimensional-LBP">here</a>] for more information.
            </p>
        </div>
    </div>
    <div class="row">
        <div class="col-md-12">
            <h3>FAQ</h3>
            <dl>
            <dt>How do I access the annotated images in the CACD dataset?</dt>

            <dl>The celebrities with rank 1-5 are annotated. Celebrities with rank 1-2 (totally 80 celebrities) are used for valiadation, use celebrityImageData.name{find(celebrityImageData.rank &lt;= 2)} to access the file names of these images; celebrities with rank 3-5 (totally 120 celebrities) are used for testing, use celebrityImageData.name{find(celebrityImageData.rank &gt; 2 &amp;&amp; celebrityImageData.rank &lt;=5)} to access the file names.</dl>
            </dl>
        </div>
    </div>
    <hr>
    <div class="row">
        <div class="col-md-12">
            Please contact <a href="mailto:bcsiriuschen@gmail.com">Sirius Chen</a> for any questions/problems/bug reports/etc.
        </div>
    </div>
</div>
<script src="http://netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>
</body>
</html>
